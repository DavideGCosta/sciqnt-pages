"use strict";(self.webpackChunksciqnt_pages=self.webpackChunksciqnt_pages||[]).push([[4505],{9046:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var t=i(4848),s=i(8453);const o={},a="Sourcing Financial News",r={id:"documentation/strategies/financial-news/sourcing-news",title:"Sourcing Financial News",description:"The world of finance is inextricably linked with the world of news, each influencing the other in a never-ending dance. Many \u2018financial market engineers\u2019 strive to decode this relationship, but the first step is collecting the right financial news data. How do you do that? Where do you start? Here, we\u2019ve laid out a quick, cost-free setup to get you started on gathering and analyzing financial news. Perfect for those looking to dive into the intricate web of market trends and news without spending a dime.",source:"@site/docs/documentation/strategies/01-financial-news/01-sourcing-news.md",sourceDirName:"documentation/strategies/01-financial-news",slug:"/documentation/strategies/financial-news/sourcing-news",permalink:"/sciqnt-pages/docs/documentation/strategies/financial-news/sourcing-news",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/documentation/strategies/01-financial-news/01-sourcing-news.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Financial News Strategy",permalink:"/sciqnt-pages/docs/category/financial-news-strategy"},next:{title:"Sentence Embeddings",permalink:"/sciqnt-pages/docs/documentation/strategies/financial-news/sentence-embeddings"}},c={},l=[{value:"Background",id:"background",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Ingesting Financial News",id:"ingesting-financial-news",level:2},{value:"Financial News Sources",id:"financial-news-sources",level:3},{value:"Financial News Semantic Search",id:"financial-news-semantic-search",level:3},{value:"Collecting the Data",id:"collecting-the-data",level:3},{value:"Financial News Stats",id:"financial-news-stats",level:3},{value:"Interesting Stats",id:"interesting-stats",level:3},{value:"Most Common Keywords in Titles",id:"most-common-keywords-in-titles",level:4},{value:"Most Common Sources",id:"most-common-sources",level:4},{value:"Most Common Topics",id:"most-common-topics",level:4}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"sourcing-financial-news",children:"Sourcing Financial News"}),"\n",(0,t.jsx)(n.p,{children:"The world of finance is inextricably linked with the world of news, each influencing the other in a never-ending dance. Many \u2018financial market engineers\u2019 strive to decode this relationship, but the first step is collecting the right financial news data. How do you do that? Where do you start? Here, we\u2019ve laid out a quick, cost-free setup to get you started on gathering and analyzing financial news. Perfect for those looking to dive into the intricate web of market trends and news without spending a dime."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/DavideGCosta/sciqnt-pages/tree/main/static/notebooks/docs/strategies/01-financial-news/01-sourcing-news.ipynb",children:(0,t.jsx)(n.img,{src:"https://img.shields.io/badge/%7C%20-Open%20in%20GitHub-blue?logo=github",alt:"Open in GitHub"})}),"\n",(0,t.jsx)(n.a,{href:"https://colab.research.google.com/github/DavideGCosta/sciqnt-pages/blob/tree/main/static/notebooks/docs/strategies/01-financial-news/01-sourcing-news.ipynb",children:(0,t.jsx)(n.img,{src:"https://img.shields.io/badge/%7C-Open%20in%20Colab-orange?style=flat&logo=googlecolab",alt:"Open in Colab"})}),"\n",(0,t.jsx)(n.a,{href:"https://github1s.com/DavideGCosta/sciqnt-pages/tree/main/static/notebooks/docs/strategies/01-financial-news/01-sourcing-news.ipynb",children:(0,t.jsx)(n.img,{src:"https://img.shields.io/badge/%7C-Open%20in%20Codespaces-darkblue?style=flat&logo=git-for-windows&logoColor=white",alt:"Open in Codespaces"})})]}),"\n",(0,t.jsx)(n.h2,{id:"background",children:"Background"}),"\n",(0,t.jsx)(n.p,{children:"In the fast-paced world of financial news and behavioral finance, each piece of information contains both fundamental and non-fundamental elements. The challenge lies in sifting through the overwhelming noise and massive influx of data that surpass human processing capabilities. But what if we could identify patterns within this data? Better yet, what if we could use computers to do it for us? Today, we are fortunate to have access to open-source models that make text comprehensible to machines. This process, known as \u2018Sentence Embeddings,\u2019 has revolutionized AI and deep learning. By converting textual data into meaningful numerical representations, sentence embeddings empower us to discern market sentiment, spot emerging trends, and predict financial movements with unprecedented efficiency and accuracy."}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(n.p,{children:"The first step in building a strategy that leans on financial news to analyze patterns and market sentiment is sourcing and ingesting those news items. Just like any data-driven analysis, the quality of your input data determines the quality of your output. Remember, garbage in, garbage out; no state-of-the-art model can compensate for poor data."}),"\n",(0,t.jsx)(n.p,{children:"So, what makes a good dataset of financial news?"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Comprehensive Coverage:"})," It should pull from a wide range of sources, including major financial news outlets and industry-specific publications. This ensures a broad perspective on market events and sentiments."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Timeliness:"})," Financial markets move quickly, so the dataset should be updated frequently to capture the latest news and developments. Real-time or near real-time data is ideal."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Relevance:"})," The news articles should be pertinent to the financial markets, covering topics like stock market updates, economic indicators, corporate earnings, mergers and acquisitions, regulatory changes, and geopolitical events."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Diversity of Perspectives:"})," Including news from various geographical regions and economic sectors can provide a more holistic view of the market. This helps in understanding global market dynamics and sector-specific trends."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Quality and Credibility:"})," The sources should be reputable and known for their accuracy and reliability. This reduces the risk of misinformation affecting analysis and investment decisions."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Metadata:"})," Each news item should come with useful metadata, such as publication date, source, author, geographical region, and topic tags. This aids in filtering, sorting, and analyzing the data more effectively."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Sentiment Analysis Ready:"})," The dataset should be in a format conducive to natural language processing and sentiment analysis. Clean, well-structured text data with minimal noise is ideal."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Historical Data:"})," Access to historical news data allows for trend analysis over time, which can be crucial for identifying long-term patterns and correlations."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"By ensuring these characteristics, a financial news dataset becomes a robust tool for analyzing market conditions and identifying investment opportunities."}),"\n",(0,t.jsx)(n.h2,{id:"ingesting-financial-news",children:"Ingesting Financial News"}),"\n",(0,t.jsx)(n.h3,{id:"financial-news-sources",children:"Financial News Sources"}),"\n",(0,t.jsx)(n.p,{children:"For instance, a solid and relevant pool of Financial News Providers might look something like this. We\u2019ve got the usual suspects with broad, comprehensive coverage, but we also delve into niche territory with specialized providers for Technology, Commodity and Energy Markets, and Healthcare. This mix ensures we\u2019re not missing out on the big picture while keeping an eye on the nitty-gritty details in specific sectors."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'news_sources = {\n    "General": {\n        "Reuters": "reuters.com",\n        "Financial Times": "ft.com",\n        "CNBC": "cnbc.com",\n        "MarketWatch": "marketwatch.com",\n        "The Economist": "economist.com",\n        "Yahoo Finance": "finance.yahoo.com",\n        "Benzinga": "benzinga.com",\n        "Investing.com": "investing.com",\n    },\n    "Technology Trends": {\n        "Wired": "wired.com",\n        "Ars Technica": "arstechnica.com",\n    },\n    "Commodity and Energy Markets": {\n        "OilPrice": "oilprice.com",\n        "Rigzone": "rigzone.com",\n    },\n    "Healthcare Developments": {\n        "Modern Healthcare": "modernhealthcare.com",\n        "BioSpace": "biospace.com",\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"financial-news-semantic-search",children:"Financial News Semantic Search"}),"\n",(0,t.jsx)(n.p,{children:"Alternatively, or as a complement to the previous sources, you can dive into the world of semantic search by keywords in financial news. This method casts a wide net, scooping up news from virtually any source, offering an impressively comprehensive search. However, there\u2019s a catch\u2014it also dredges up a fair share of irrelevant news and content from potentially dubious providers. So, before you dive into analysis, you\u2019ll need a solid spam filter to sift out the noise and ensure you\u2019re not swimming in a sea of non-credible stuff."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'news_topics = {\n    "Market Dynamics": {\n        "Title": "Market Dynamics",\n        "Description": "Exploring the various factors that influence financial markets, including interest rates, inflation, employment, economic growth, consumer spending, and the housing market.",\n        "Subtopics": {\n            "Interest Rates": {\n                "Title": "Interest Rates & Monetary Policy",\n                "Description": "An analysis of how interest rates and central bank policies influence financial markets.",\n                "Keywords": "\\"Interest Rate\\" OR \\"Federal Reserve\\" OR \\"FED\\" OR \\"Central Bank\\""\n            } # add more ...\n        }\n    },\n    "Geopolitical Events": {\n        "Title": "Geopolitical Events",\n        "Description": "Insights into key global political events, including elections, trade dynamics, international relations, military conflicts, EU matters, and global summits.",\n        "Subtopics": {\n            "Elections": {\n                "Title": "Global Elections",\n                "Description": "Coverage of major elections and political campaigns worldwide.",\n                "Keywords": "\\"Election\\" OR \\"Political Campaign\\" OR \\"Political Development\\""\n            } # add more ...\n        }\n    },\n    "Regulatory Changes": {\n        "Title": "Regulatory Changes",\n        "Description": "Tracking significant shifts in tax, monetary and fiscal policies, antitrust, environmental, and financial regulations.",\n        "Subtopics": {\n            "Tax Policies": {\n                "Title": "Tax Policy Changes",\n                "Description": "Updates on tax reforms, legislation, and changes in tax policies.",\n                "Keywords": "\\"Tax Reform\\" OR \\"Tax Legislation\\" OR \\"Tax Policy\\" OR \\"Tax Cut\\" OR \\"Tax Hike\\""\n            }# add more ...\n        }\n    },\n    "Technology Trends": {\n        "Title": "Technology Trends",\n        "Description": "Insights into the latest advancements in AI, blockchain, cybersecurity, telecommunication, automotive, and renewable energy technologies.",\n        "Subtopics": {\n            "AI and Machine Learning": {\n                "Title": "AI and Machine Learning Innovations",\n                "Description": "Exploring advancements in artificial intelligence and machine learning technologies.",\n                "Keywords": "\\"Artificial Intelligence\\" OR \\"Machine Learning\\" OR \\"AI ML\\""\n            } # add more ...\n        }\n    },\n    "Corporate Actions": {\n        "Title": "Corporate Actions",\n        "Description": "A focus on financial reports, mergers, public offerings, stock activities, and dividend policies of corporations.",\n        "Subtopics": {\n            "Financial Reports": {\n                "Title": "Corporate Financial Reporting",\n                "Description": "Analysis of earnings reports, financial statements, and annual and quarterly reports.",\n                "Keywords": "\\"Earnings\\" OR \\"Earnings Report\\" OR \\"Financial Statement\\" OR \\"Quarterly Report\\" OR \\"Annual Report\\" OR \\"10-K\\" OR \\"10-Q\\""\n            }# add more ...\n        }\n    },\n    "Commodity and Energy Markets": {\n        "Title": "Commodity and Energy Markets",\n        "Description": "In-depth analysis of commodity markets including oil, precious metals, agricultural commodities, and renewable energy sources.",\n        "Subtopics": {\n            "Oil and Petroleum": {\n                "Title": "Oil and Petroleum Dynamics",\n                "Description": "Exploration of the oil and petroleum markets, focusing on trends and economic impacts.",\n                "Keywords": "\\"Oil\\" OR \\"Crude\\" OR \\"Petroleum\\" OR \\"Energy\\""\n            }# add more ...\n        }\n    },\n    "Healthcare Developments": {\n        "Title": "Healthcare Developments",\n        "Description": "Exploration of key factors in healthcare including pandemics, medical innovations, health policies, and pharmaceutical advances.",\n        "Subtopics": {\n            "Pandemics": {\n                "Title": "Pandemic Outbreaks",\n                "Description": "Focus on the impact and management of global health crises and pandemics.",\n                "Keywords": "\\"Pandemic Outbreak\\" OR \\"Global Health Crisis\\""\n            } # add more ...\n        }\n    },\n    "Environmental and Social Issues": {\n        "Title": "Environmental and Social Issues",\n        "Description": "Focus on critical environmental and social challenges like climate change, sustainable investing, corporate governance, and social movements.",\n        "Subtopics": {\n            "Climate Change": {\n                "Title": "Climate Change Impacts",\n                "Description": "Analysis of climate change effects and the response to global warming.",\n                "Keywords": "\\"Climate Change\\" OR \\"Global Warming\\" OR \\"Carbon Emission\\" OR \\"Carbon Tax\\""\n            }# add more ...\n        }\n    },\n    "Market Sentiment Indicators": {\n        "Title": "Market Sentiment Indicators",\n        "Description": "A comprehensive look at the indicators that reflect market sentiment, including volatility, options market, short selling, and market surveys.",\n        "Subtopics": {\n            "Market Volatility": {\n                "Title": "Market Volatility Analysis",\n                "Description": "Analysis of market volatility and its implications for investors and traders.",\n                "Keywords": "\\"Volatility Index\\" OR \\"VIX\\" OR \\"Market Volatility\\""\n            }# add more ...\n        }\n    },\n    "Economic Indicators": {\n        "Title": "Economic Indicators",\n        "Description": "Analysis of key economic indicators including PMI, consumer prices, housing market, and industrial production.",\n        "Subtopics": {\n            "Purchasing Managers Index": {\n                "Title": "Purchasing Managers Index Insights",\n                "Description": "In-depth analysis of the PMI and its implications for the economy.",\n                "Keywords": "\\"Purchasing Managers\' Index\\" OR \\"PMI\\""\n            },\n            "Consumer Prices": {\n                "Title": "Consumer Price Trends",\n                "Description": "Examination of consumer price indices and inflation.",\n                "Keywords": "\\"Consumer Price Index\\" OR \\"Inflation\\" OR \\"CPI\\""\n            }# add more ...\n        }\n    }\n}\n\n'})}),"\n",(0,t.jsx)(n.h3,{id:"collecting-the-data",children:"Collecting the Data"}),"\n",(0,t.jsx)(n.p,{children:"Now that we\u2019ve identified our sources and keywords, it\u2019s time to pull the news data. There are several methods to do this, ranging from free to premium, but let\u2019s focus on the budget-friendly options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Financial News APIs:"})," Free tiers of services like Alpha Vantage, NewsAPI, and Finnhub provide real-time and historical financial news data. This method offers the simplest access but can be limited in scope and data availability."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Web Scraping:"})," Build your own web scrapers using tools like Beautiful Soup or Scrapy in Python to extract data from financial news websites. However, this requires adherence to each site\u2019s scraping policies, and handling captchas and logins can make it quite challenging."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"RSS Feeds:"})," Some sources offer free RSS feeds you can subscribe to for pulling information. The downside is you\u2019ll need to handle each source individually, and not all sources provide RSS feeds."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"News Aggregators:"})," Platforms like Google News and Feedly consolidate news from multiple sources in one place, standardizing the information. While they typically offer only news titles, summaries, and metadata, this is often sufficient for initial analysis."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Google News also provides an RSS feed, simplifying the process of pulling financial news. For this reason, we\u2019ll use it as our example."}),"\n",(0,t.jsxs)(n.p,{children:["By running the snippet below you can leverage the Google News Aggregator to pull the financial news for your ",(0,t.jsx)(n.code,{children:"news_sources"})," and ",(0,t.jsx)(n.code,{children:"news_topics"})," defined above."]}),"\n",(0,t.jsx)(n.p,{children:"The snippet can be split as follows:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"make_DTawareUCT"}),": Imagine you\u2019ve got a bunch of datetime strings lounging around with no clue what timezone they belong to. That\u2019s where this function steps in, takes these naive datetime strings, and whisks them into the UTC timezone."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"clean_description"}),": You know how news descriptions come plastered with HTML tags and clutter? Using BeautifulSoup, it scrapes off all those pesky tags and unwanted spaces, leaving behind just the clean, pure text. It\u2019s like giving your news description a nice shower, ready for the spotlight in your analysis."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"get_googleNewsRss"}),": Now, here\u2019s the main event. This function crafts a search URL with all your secret ingredients\u2014topics, subtopics, keywords, and timing. It then sends this URL out into the web and waits for the XML data to come back. Once it\u2019s got the goods, it parses through the XML, picking out relevant bits like titles, links, descriptions, and sources. It even checks the publication date\u2019s timezone and cleans up the description\u2019s HTML mess. Each piece of news gets its own little data packet, and before you know it, you\u2019ve got a DataFrame full of fresh, neatly organized news articles."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'%%capture\n# Install the necessary packages\n!pip install requests pandas beautifulsoup4 lxml pytz tabulate\n\nimport warnings, os\n# Suppress all warnings - remove it when testing the notebook to see the warnings\nwarnings.simplefilter("ignore")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Importing the necessary dependencies\nimport requests\nimport xml.etree.ElementTree as ET\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom datetime import datetime\nimport pytz\nimport random\n\n# Convert naive datetimes to aware datetimes in UTC\ndef make_DTawareUCT(naive_datetime_str, dtformat):\n    naive_datetime = datetime.strptime(naive_datetime_str, dtformat)\n    aware_datetime = pytz.utc.localize(naive_datetime)\n    return aware_datetime\n\n# Clean HTML content in news descriptions \ndef clean_description(html_description):\n    if not html_description:\n        return \"\"\n    soup = BeautifulSoup(html_description, 'html.parser')\n    # Find all text in the description and concatenate it\n    return ' '.join(soup.stripped_strings)\n\n# Fetch Google News RSS feeds\ndef get_googleNewsRss(topic='', subtopic='', keyword=False, inUrl=False, when=False, logger=False):\n    # Construct the search query URL\n    keyword_str = f\"{keyword}\" if keyword is not False else \"\"\n    inUrl_str = f\"inurl:{inUrl}\" if inUrl is not False else \"\"\n    when_str = f\"when:{when}\" if when is not False else \"\"\n    url = f\"https://news.google.com/rss/search?q={keyword_str}+{inUrl_str}+{when_str}&hl=en-US&gl=US&ceid=US:en\"\n    # Make the request to Google News RSS\n    xml_data = None\n    response = requests.get(url)\n    if response.status_code == 200:\n        xml_data = response.text\n    else:\n        raise Exception(f\"Failed to get RSS feed from {url}\")\n    if xml_data == None:\n        return pd.DataFrame()\n    else:\n        # Parse the XML data\n        root = ET.fromstring(xml_data)\n        items_list = []\n        for item in root.findall('.//item'):\n            # Extract necessary information from each item\n            title = item.find('title').text if item.find('title') is not None else None\n            link = item.find('link').text if item.find('link') is not None else None\n            description = item.find('description').text if item.find('description') is not None else None\n            source = item.find('source').text if item.find('source') is not None else None\n            pubDate = item.find('pubDate').text if item.find('pubDate') is not None else None\n            pubDate = make_DTawareUCT(pubDate, '%a, %d %b %Y %H:%M:%S GMT')\n            # Clean the description HTML content\n            clean_desc = clean_description(description)\n            item_data = {\n                'topic': topic,\n                'subtopic': subtopic,\n                'title': title,\n                'link': link,\n                'description': clean_desc,\n                'source': source,\n                'pubDate' : pubDate,\n                'tags' : keyword_str.replace(\"\\\"\", \"\").split(\" OR \") if keyword_str !=\"\" else [],\n                'Headline Event': ''\n            }\n            items_list.append(item_data)\n        newsDf = pd.DataFrame(items_list)\n    return newsDf\n\n# Example usage: \nwhen = \"1d\" # gets news from the past day -- see google news search syntax for more options\nlist_news_bySources = []\nfor topic in news_sources.keys():\n    for _, sourceUrl in news_sources[topic].items():\n        # Append news data from each source\n        list_news_bySources.append(get_googleNewsRss(topic, subtopic='', inUrl=sourceUrl, when=when))\n\nlist_news_byTopics = []\ntopics = list(news_topics.keys()) \nrandom.shuffle(topics)\nfor topic in topics:\n    topic_data = news_topics[topic]\n    # Convert subtopics to a list and shuffle\n    subtopics = list(topic_data['Subtopics'].keys())\n    random.shuffle(subtopics)\n    for subtopic in subtopics:\n        subtopic_data = topic_data['Subtopics'][subtopic]\n        # Append news data from each randomly selected subtopic\n        list_news_byTopics.append(get_googleNewsRss(topic, subtopic, keyword=subtopic_data['Keywords'], when=when))\n\nlist_AllNews = list_news_byTopics + list_news_byTopics\ndf_AllNews = pd.concat(list_AllNews, ignore_index=True)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"financial-news-stats",children:"Financial News Stats"}),"\n",(0,t.jsx)(n.p,{children:"Now that we\u2019ve meticulously gathered our financial news articles and compiled them into the df_AllNews DataFrame, it\u2019s time to dive into the data and extract some meaningful insights. With a rich dataset at our disposal, we can move beyond merely collecting news to analyzing it for patterns, trends, and actionable intelligence. To achieve this, we\u2019ll utilize the show_interesting_stats function, which will provide a comprehensive overview of our dataset. This function will dissect the DataFrame, revealing the number of articles, the diversity of sources, the time span of the news, and the most frequently mentioned keywords and topics. By examining these statistics, we can gain a clearer understanding of the current financial news landscape and uncover the dominant narratives shaping the market."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from collections import Counter\nimport re\n\ndef extract_keywords_from_title(title):\n    # Simple keyword extraction by splitting words and removing common stopwords\n    stopwords = set(['and', 'or', 'the', 'in', 'on', 'a', 'an', 'for', 'with', 'of', 'to', 'by'])\n    words = re.findall(r'\\w+', title.lower())\n    keywords = [word for word in words if word not in stopwords and len(word) > 2]\n    return keywords\n\ndef show_interesting_stats(df):\n    if df.empty:\n        print(\"# The DataFrame is empty.\")\n        return\n\n    # Number of articles\n    num_articles = len(df)\n    \n    # Number of unique sources\n    num_sources = df['source'].nunique()\n    \n    # Time range covered by the articles\n    min_date = df['pubDate'].min()\n    max_date = df['pubDate'].max()\n    \n    # Most common sources\n    sources_counts = df['source'].value_counts().head(5)\n    \n    # Extract keywords from titles\n    all_keywords = df['title'].apply(lambda title: extract_keywords_from_title(title))\n    keyword_counts = Counter([keyword for keywords in all_keywords for keyword in keywords]).most_common(5)\n    \n    # Most common topics\n    topic_counts = df['topic'].value_counts().head(5)\n    \n    print(f\"### Interesting Stats\")\n    print(f\"- **Number of articles:** {num_articles}\")\n    print(f\"- **Number of unique sources:** {num_sources}\")\n    print(f\"- **Time range covered:** {min_date} to {max_date}\")\n    \n    print(\"\\n#### Most Common Keywords in Titles\")\n    for keyword, count in keyword_counts:\n        print(f\"- **{keyword}:** {count}\")\n    \n    print(\"\\n#### Most Common Sources\")\n    for source, count in sources_counts.items():\n        print(f\"- **{source}:** {count}\")\n    \n    print(\"\\n#### Most Common Topics\")\n    for topic, count in topic_counts.items():\n        print(f\"- **{topic}:** {count}\")\n\n# Example usage\nshow_interesting_stats(df_AllNews)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"interesting-stats",children:"Interesting Stats"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Number of articles:"})," 1512"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Number of unique sources:"})," 368"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Time range covered:"})," 2024-07-10 19:42:15+00:00 to 2024-07-11 19:34:30+00:00"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"most-common-keywords-in-titles",children:"Most Common Keywords in Titles"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"inflation:"})," 244"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"news:"})," 194"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"climate:"})," 186"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"earnings:"})," 172"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"change:"})," 162"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"most-common-sources",children:"Most Common Sources"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Yahoo Finance:"})," 136"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bloomberg:"})," 58"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reuters:"})," 58"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"MarketWatch:"})," 42"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ABC News:"})," 36"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"most-common-topics",children:"Most Common Topics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Economic Indicators:"})," 222"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Environmental and Social Issues:"})," 194"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Technology Trends:"})," 194"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Market Dynamics:"})," 182"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Corporate Actions:"})," 182"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"That's all. The really cool stuff comes from employing machine learning models to the dataset - take a look at our next articles for an understanding of how to do it."})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>r});var t=i(6540);const s={},o=t.createContext(s);function a(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);